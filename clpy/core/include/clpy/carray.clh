#pragma once
#pragma OPENCL EXTENSION cl_khr_fp16: enable

// TODO: Implement common functions in OpenCL C
#if 0
// math
#ifndef M_PI
#define M_PI 3.1415926535897932384626433832795
#endif

#if __CUDACC_VER_MAJOR__ < 9

// float16
class float16
{
private:
  unsigned short data_;
public:
  __device__ float16() {}
  __device__ float16(float v) {
    data_ = __float2half_rn(v);
  }
  explicit __device__ float16(bool v) {
    data_ = __float2half_rn(static_cast<float>(v));
  }
  explicit __device__ float16(double v) {
    data_ = __float2half_rn(static_cast<float>(v));
  }
  explicit __device__ float16(int v) {
    data_ = __float2half_rn(static_cast<float>(v));
  }
  explicit __device__ float16(unsigned int v) {
    data_ = __float2half_rn(static_cast<float>(v));
  }
  explicit __device__ float16(long long v) {
    data_ = __float2half_rn(static_cast<float>(v));
  }
  explicit __device__ float16(unsigned long long v) {
    data_ = __float2half_rn(static_cast<float>(v));
  }

  __device__ operator float() const {return __half2float(data_);}

  static const unsigned short nan = 0x7e00u;

  __device__ int iszero() const {
    return (data_ & 0x7fff) == 0;
  }

  __device__ int isnan() const {
    return (data_ & 0x7c00u) == 0x7c00u && (data_ & 0x03ffu) != 0x0000u;
  }

  __device__ int isinf() const {
    return (data_ & 0x7fffu) == 0x7c00u;
  }

  __device__ int isfinite() const {
    return (data_ & 0x7c00u) != 0x7c00u;
  }

  __device__ int signbit() const
  {
    return (data_ & 0x8000u) != 0;
  }

  template<typename T>
  inline __device__ float16& operator+=(const T& rhs)
  {
    *this = *this + rhs;
    return *this;
  }

  template<typename T>
  inline __device__ float16& operator-=(const T& rhs)
  {
    *this = *this - rhs;
    return *this;
  }

  template<typename T>
  inline __device__ float16& operator*=(const T& rhs)
  {
    *this = *this * rhs;
    return *this;
  }

  template<typename T>
  inline __device__ float16& operator/=(const T& rhs)
  {
    *this = *this / rhs;
    return *this;
  }

  friend __device__ float16 copysign(float16 x, float16 y) {
    float16 ret;
    ret.data_ = (x.data_ & 0x7fffu) | (y.data_ & 0x8000u);
    return ret;
  }

  friend __device__ float16 nextafter(float16 x, float16 y) {
    float16 ret;
    if (!x.isfinite() || y.isnan()) {
      ret.data_ = nan;
    } else if (eq_nonan(x, y)) {
      ret = x;
    } else if (x.iszero()) {
      ret.data_ = (y.data_ & 0x8000u) + 1;
    } else if (!(x.data_ & 0x8000u)) {
      if (static_cast<short>(x.data_) > static_cast<short>(y.data_)) {
        ret.data_ = x.data_ - 1;
      } else {
        ret.data_ = x.data_ + 1;
      }
    } else if(!(y.data_ & 0x8000u) || (x.data_ & 0x7fffu) > (y.data_ & 0x7fffu)) {
      ret.data_ = x.data_ - 1;
    } else {
      ret.data_ = x.data_ + 1;
    }
    return ret;
  }

private:
  static __device__ int eq_nonan(const float16 x, const float16 y) {
    return (x.data_ == y.data_ || ((x.data_ | y.data_) & 0x7fff) == 0);
  }
};

#else  // #if __CUDACC_VER_MAJOR__ < 9

#include <cuda_fp16.h>

// float16
class float16
{
private:
    half  data_;
public:
  __device__ float16() {}
  __device__ float16(float v) {
    data_ = __half(v);
  }

  explicit __device__ float16(bool v) {
    data_ = __float2half_rn(static_cast<short>(v));
  }
  explicit __device__ float16(double v) {
    data_ = __half(v);
  }
  explicit __device__ float16(int v) {
    data_ = __half(v);
  }
  explicit __device__ float16(unsigned int v) {
    data_ = __half(v);
  }
  explicit __device__ float16(long long v) {
    data_ = __half(v);
  }
  explicit __device__ float16(unsigned long long v) {
    data_ = __half(v);
  }
  explicit __device__ float16(half v) {
    data_ = v;
  }

  __device__ operator float() const {return __half2float(data_);}

  static const unsigned short nan = 0x7e00u;

  __device__ int iszero() const {
    __half_raw raw_ = __half_raw(data_);
    return (raw_.x & 0x7fff) == 0;
  }

  __device__ int isnan() const {
    __half_raw raw_ = __half_raw(data_);
    return (raw_.x & 0x7c00u) == 0x7c00u && (raw_.x & 0x03ffu) != 0x0000u;
  }

  __device__ int isinf() const {
    __half_raw raw_ = __half_raw(data_);
    return (raw_.x & 0x7fffu) == 0x7c00u;
  }

  __device__ int isfinite() const {
    __half_raw raw_ = __half_raw(data_);
    return (raw_.x & 0x7c00u) != 0x7c00u;
  }

  __device__ int signbit() const
  {
    __half_raw raw_ = __half_raw(data_);
    return (raw_.x & 0x8000u) != 0;
  }

  template<typename T>
  inline __device__ float16& operator+=(const T& rhs)
  {
    *this = *this + rhs;
    return *this;
  }

  template<typename T>
  inline __device__ float16& operator-=(const T& rhs)
  {
    *this = *this - rhs;
    return *this;
  }

  template<typename T>
  inline __device__ float16& operator*=(const T& rhs)
  {
    *this = *this * rhs;
    return *this;
  }

  template<typename T>
  inline __device__ float16& operator/=(const T& rhs)
  {
    *this = *this / rhs;
    return *this;
  }

  friend __device__ float16 copysign(float16 x, float16 y) {
    float16 ret;
    __half_raw x_raw_ = __half_raw(x.data_);
    __half_raw y_raw_ = __half_raw(y.data_);
    __half_raw ret_raw_;
    ret_raw_.x = (x_raw_.x & 0x7fffu) | (y_raw_.x & 0x8000u);
    ret.data_ = ret_raw_;
    return ret;
  }

  friend __device__ float16 nextafter(float16 x, float16 y) {
    float16 ret;
    __half_raw x_raw_ = __half_raw(x.data_);
    __half_raw y_raw_ = __half_raw(y.data_);
    __half_raw ret_raw_;
    if (!x.isfinite() || y.isnan()) {
      ret_raw_.x = nan;
    } else if (eq_nonan(x, y)) {
      ret_raw_.x = x_raw_.x;
    } else if (x.iszero()) {
      ret_raw_.x = (y_raw_.x & 0x8000u) + 1;
    } else if (!(x_raw_.x & 0x8000u)) {
      if (x_raw_.x > y_raw_.x) {
	ret_raw_.x = x_raw_.x - 1;
      } else {
	ret_raw_.x = x_raw_.x + 1;
      }
    } else if(!(y_raw_.x & 0x8000u) || (x_raw_.x & 0x7fffu) > (y_raw_.x & 0x7fffu)) {
      ret_raw_.x = x_raw_.x - 1;
    } else {
      ret_raw_.x = x_raw_.x + 1;
    }
    ret.data_ = ret_raw_;
    return ret;
  }

private:
  static __device__ int eq_nonan(const float16 x, const float16 y) {
    __half_raw x_raw_ = __half_raw(x.data_);
    __half_raw y_raw_ = __half_raw(y.data_);
    return (x_raw_.x == y_raw_.x || ((x_raw_.x | y_raw_.x) & 0x7fff) == 0);
  }
};

#endif  // #if __CUDACC_VER_MAJOR__ < 9

__device__ float16 min(float16 x, float16 y) {
  return float16(min(static_cast<float>(x), static_cast<float>(y)));
}
__device__ float16 max(float16 x, float16 y) {
  return float16(max(static_cast<float>(x), static_cast<float>(y)));
}
__device__ int iszero(float16 x) {return x.iszero();}
__device__ int isnan(float16 x) {return x.isnan();}
__device__ int isinf(float16 x) {return x.isinf();}
__device__ int isfinite(float16 x) {return x.isfinite();}
__device__ int signbit(float16 x) {return x.signbit();}

#endif

#define CREATE_CINDXER(_NDIM) \
typedef struct { \
  size_t size_; \
  size_t shape_[_NDIM]; \
  size_t index_[_NDIM]; \
} CIndexer_##_NDIM; \
\
static size_t size_CIndexer_##_NDIM(const CIndexer_##_NDIM * const __restrict__ _ind) { \
  return _ind->size_; \
} \
\
static void set_CIndexer_##_NDIM(CIndexer_##_NDIM * const __restrict__ _ind, const size_t i) { \
  size_t a = i; \
  for (size_t dim = _NDIM - 1; dim > 0; --dim) { \
    const size_t s = _ind->shape_[dim]; \
    (_ind->index_)[dim] = a % s; \
    a /= s; \
  } \
  _ind->index_[0] = a; \
}

typedef struct {
  size_t size_;
} CIndexer_0;
static size_t size_CIndexer_0(const CIndexer_0 * const __restrict__ _ind) {
  return _ind->size_;
}
static void set_CIndexer_0(CIndexer_0 * const __restrict__ _ind, const size_t i) {
}

typedef struct {
  size_t size_;
  size_t shape_;
  size_t index_;
} CIndexer_1;
static size_t size_CIndexer_1(const CIndexer_1 * const __restrict__ _ind) {
  return _ind->size_;
}
static void set_CIndexer_1(CIndexer_1 * const __restrict__ _ind, const size_t i) {
  _ind->index_ = i;
}

// CIndexr_0 is defined above
// CIndexr_1 is defined above
CREATE_CINDXER(2)
CREATE_CINDXER(3)
CREATE_CINDXER(4)
CREATE_CINDXER(5)
CREATE_CINDXER(6)
CREATE_CINDXER(7)
CREATE_CINDXER(8)
CREATE_CINDXER(9)
CREATE_CINDXER(10)
CREATE_CINDXER(11)
CREATE_CINDXER(12)
CREATE_CINDXER(13)
CREATE_CINDXER(14)
CREATE_CINDXER(15)

#undef CREATE_CINDEXER

#define CREATE_CARRAY(_NDIM) \
typedef struct { \
  size_t offset; \
  size_t size_; \
  size_t shape_[_NDIM]; \
  size_t strides_[_NDIM]; \
} CArray_##_NDIM; \
size_t get_CArrayIndexI_##_NDIM(const CArray_##_NDIM* const __restrict__ info, const size_t i) { \
  size_t offset = info->offset; \
  size_t ii = i; \
  for (size_t dim = _NDIM - 1; dim > 0; --dim) { \
    offset += info->strides_[dim] * (ii % info->shape_[dim]); \
    ii /=  info->shape_[dim]; \
  } \
  offset += info->strides_[0] * ii; \
  return offset; \
}

typedef struct {
  size_t offset;
  size_t size_;
} CArray_0;
static size_t get_CArrayIndexRaw_0(const CArray_0* const __restrict__ info, const ptrdiff_t idx) {
  return info->offset;
}
static size_t get_CArrayIndex_0(const CArray_0* const __restrict__ info, const CIndexer_0* const __restrict__ _ind) {
  return get_CArrayIndexRaw_0(info, 0);
}
static size_t get_CArrayIndexI_0(const CArray_0* const __restrict__ info, const size_t i) {
  return info->offset;
}

typedef struct {
  size_t offset;
  size_t size_;
  size_t shape_;
  size_t strides_;
} CArray_1;
static size_t get_CArrayIndexRaw_1(const CArray_1* const __restrict__ info, const ptrdiff_t idx) {
  return info->strides_ * (size_t)idx + info->offset;
}
static size_t get_CArrayIndex_1(const CArray_1* const __restrict__ info, const CIndexer_1* const __restrict__ _ind) {
  return get_CArrayIndexRaw_1(info, _ind->index_);
}
static size_t get_CArrayIndexI_1(const CArray_1* const __restrict__ info, const size_t i) {
  return info->strides_ * i + info->offset;
}

// CArray_0 is defined above
// CArray_1 is defined above
CREATE_CARRAY(2)
CREATE_CARRAY(3)
CREATE_CARRAY(4)
CREATE_CARRAY(5)
CREATE_CARRAY(6)
CREATE_CARRAY(7)
CREATE_CARRAY(8)
CREATE_CARRAY(9)
CREATE_CARRAY(10)
CREATE_CARRAY(11)
CREATE_CARRAY(12)
CREATE_CARRAY(13)
CREATE_CARRAY(14)
CREATE_CARRAY(15)

#undef CREATE_CARRAY

#ifdef __ULTIMA
#define CREATE_CARRAY_FUNCTION(_NDIM) \
template<typename T>\
static size_t get_CArrayIndexRaw_##_NDIM(const CArray_##_NDIM* const __restrict__ info, const T* idx) { \
  size_t offset = info->offset; \
  for (size_t dim = 0; dim < _NDIM; dim++) { \
    offset += info->strides_[dim] * idx[dim]; \
  } \
  return offset; \
}\
static size_t get_CArrayIndex_##_NDIM(const CArray_##_NDIM* const __restrict__ info, const CIndexer_##_NDIM* const __restrict__ _ind) { \
  return get_CArrayIndexRaw_##_NDIM(info, _ind->index_); \
}\
template size_t get_CArrayIndexRaw_##_NDIM(const CArray_##_NDIM* const __restrict__ info, const unsigned long* idx);\
template size_t get_CArrayIndexRaw_##_NDIM(const CArray_##_NDIM* const __restrict__ info, const long* idx);\
template size_t get_CArrayIndexRaw_##_NDIM(const CArray_##_NDIM* const __restrict__ info, const unsigned int* idx);\
template size_t get_CArrayIndexRaw_##_NDIM(const CArray_##_NDIM* const __restrict__ info, const int* idx);
static void __clpy_begin_print_out() __attribute__((annotate("clpy_begin_print_out")));
CREATE_CARRAY_FUNCTION(2)
CREATE_CARRAY_FUNCTION(3)
CREATE_CARRAY_FUNCTION(4)
CREATE_CARRAY_FUNCTION(5)
CREATE_CARRAY_FUNCTION(6)
CREATE_CARRAY_FUNCTION(7)
CREATE_CARRAY_FUNCTION(8)
CREATE_CARRAY_FUNCTION(9)
CREATE_CARRAY_FUNCTION(10)
CREATE_CARRAY_FUNCTION(11)
CREATE_CARRAY_FUNCTION(12)
CREATE_CARRAY_FUNCTION(13)
CREATE_CARRAY_FUNCTION(14)
CREATE_CARRAY_FUNCTION(15)
static void __clpy_end_print_out() __attribute__((annotate("clpy_end_print_out")));
#endif

#undef CREATE_CARRAY_FUNCTION

static char _floor_divide_c(const char x, const char y) {
  if (y == 0) return 0;
  const char q = x / y;
  return q - (((x < 0) != (y < 0)) && q * y != x);
}

static short _floor_divide_s(const short x, const short y) {
  if (y == 0) return 0;
  const short q = x / y;
  return q - (((x < 0) != (y < 0)) && q * y != x);
}

static int _floor_divide_i(const int x, const int y) {
  if (y == 0) return 0;
  const int q = x / y;
  return q - (((x < 0) != (y < 0)) && q * y != x);
}

static long _floor_divide_l(const long x, const long y) {
  if (y == 0) return 0;
  const long q = x / y;
  return q - (((x < 0) != (y < 0)) && q * y != x);
}

static uchar _floor_divide_C(const uchar x, const uchar y) {
  if (y == 0) return 0;
  return x / y;
}

static ushort _floor_divide_S(const ushort x, const ushort y) {
  if (y == 0) return 0;
  return x / y;
}

static uint _floor_divide_I(const uint x, const uint y) {
  if (y == 0) return 0;
  return x / y;
}

static ulong _floor_divide_L(const ulong x, const ulong y) {
  if (y == 0) return 0;
  return x / y;
}

static float _floor_divide_f(const float x, const float y) {
  return floor(x / y);
}

static double _floor_divide_d(const double x, const double y) {
  return floor(x / y);
}

// atomic operation
static void atomicAdd(__global float* x, float y)
{
  union {
    float f;
    uint u;
  } p, old_value, new_value;

  old_value.f = *x;
  do {
    new_value = old_value;
    p.f = old_value.f + y;
    old_value.u = atomic_cmpxchg((__global uint*)x, new_value.u, p.u);
  } while ( new_value.u != old_value.u );
}
// TODO(yoriyuki.kitta): Add another types implementation

#ifdef __ULTIMA
__attribute__((annotate("clpy_no_mangle"))) static half convert_float_to_half(float x);
#else
static half convert_float_to_half(float f) {
  const float scale_to_inf = 0x1.0p+112f;
  const float scale_to_zero = 0x1.0p-110f;
  float base = (fabs(f) * scale_to_inf) * scale_to_zero;

  const uint w = *(const uint*)&f;
  const uint shl1_w = w + w;
  const uint sign = w & (uint)(0x80000000);
  uint bias = shl1_w & (uint)(0xFF000000);
  if (bias < (uint)(0x71000000)) {
    bias = (uint)(0x71000000);
  }

  uint bits = (bias >> 1) + (uint)(0x07800000);
  base = *(const float*)&bits + base;
  bits = *(const uint*)&base;
  const uint exp_bits = (bits >> 13) & (uint)(0x00007C00);
  const uint mantissa_bits = bits & (uint)(0x00000FFF);
  const uint nonsign = exp_bits + mantissa_bits;
  const ushort ret = ((sign >> 16) | (shl1_w > (uint)(0xFF000000) ? (ushort)(0x7E00) : nonsign));
  return *(const half*)&ret;
}
typedef half __clpy__half;
#endif
